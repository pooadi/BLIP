{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOeiJacGMt7yh7r50ljKQt3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2F6pHle6S1V_"},"outputs":[],"source":["# code to mount my drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# install the necessary requirements\n","!pip3 install timm==0.4.12 fairscale==0.4.4\n","!pip3 install transformers\n","!pip install pycocoevalcap\n","!pip install ruamel.yaml"],"metadata":{"id":"RIcSo_9ZTPwz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**This section is for running an inference instant of BLIP**\n","\n"],"metadata":{"id":"fKZQFsPnUuNy"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/My_Software_Projects/BLIP\n","!pip install -Uqq ipdb\n","import ipdb"],"metadata":{"id":"OcUm83MxY-XB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pdb on"],"metadata":{"id":"YOtJbX4HiZTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import requests\n","import torch\n","from torchvision import transforms\n","from torchvision.transforms.functional import InterpolationMode\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def load_demo_image(image_size,device):\n","    img_url = '/content/drive/MyDrive/My_Software_Projects/Input_Frames/time0_frame1.jpg'\n","    raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n","\n","    w,h = raw_image.size\n","    display(raw_image.resize((w//5,h//5)))\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n","        ])\n","    image = transform(raw_image).unsqueeze(0).to(device)\n","    return image"],"metadata":{"id":"fEQ9Ez71UfO9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Code to run an inference on the BLIP image captioning network from a video file**"],"metadata":{"id":"lFQpveR-Fd8w"}},{"cell_type":"code","source":["from models.blip import blip_decoder\n","from PIL import Image\n","import requests\n","import torch\n","from torchvision import transforms\n","from torchvision.transforms.functional import InterpolationMode\n","import cv2\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def load_demo_image(image_size,device, raw_image):\n","\n","    # img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\n","    # raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n","    img_url = '/content/drive/My Drive/My_Software_Projects/Input_Frames/time0_frame1.jpg'\n","    # raw_image = Image.open(img_url).convert('RGB')\n","    # raw_image = cv2.imread(img_url)\n","    raw_image = raw_image\n","    raw_image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n","    raw_image = Image.fromarray(raw_image)\n","\n","\n","    w,h = raw_image.size\n","    display(raw_image.resize((w//5,h//5)))\n","    #cv2.imshow('image', raw_image)\n","\n","    transform = transforms.Compose([\n","        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n","        ])\n","    image = transform(raw_image).unsqueeze(0).to(device)\n","    return image\n","\n","\n","\n","#path to input Video File\n","pathToInputVideoFile = '/content/drive/My Drive/My_Software_Projects/Input_Video/InputVideo2.mp4'\n","\n","#path to the output Folder\n","pathToOutputFramesFolder = '/content/drive/My Drive/My_Software_Projects/Output/Output_Caption/'\n","\n","# path to the output text File\n","pathToOutputTxtFile = '/content/drive/My Drive/My_Software_Projects/Output_File/CaptionTextFile.txt'\n","\n","# initialise path file\n","outputTextFile = open(pathToOutputTxtFile, 'w')\n","\n","# set image size\n","image_size = 384\n","\n","#Loading the model file\n","model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n","\n","\n","\n","model = blip_decoder(pretrained=model_url, image_size=image_size, vit='base')\n","model.eval()\n","model = model.to(device)\n","print(\"Model Successfully Loaded.\")\n","\n","print(\"Loading Input Video File.....\")\n","inputVideo = cv2.VideoCapture(pathToInputVideoFile)\n","print(\"Successfully Loaded input File\")\n","\n","\n","# Calculate the Frames per second (FPS)\n","print(\"Calculating Frames Per Second...\")\n","fps = round(inputVideo.get(cv2.CAP_PROP_FPS))\n","print('Fps = ' + str(fps))\n","\n","frameNumber = 0\n","timeStamp = 0\n","\n","print('Processing Frames...')\n","\n","\n","while True:\n","  # Processing Frames\n","  success, imageFrame = inputVideo.read()\n","\n","  if success:\n","    # increase the frame by 1\n","    frameNumber += 1\n","\n","    image = load_demo_image(image_size=image_size, device=device, raw_image=imageFrame)\n","\n","    with torch.no_grad():\n","      # ipdb.set_trace(context=6)\n","      # beam search (not working atm)\n","      # caption = model.generate(image, sample=False, num_beams=3, max_length=20, min_length=5)\n","\n","      # nucleus sampling\n","      caption = model.generate(image, sample=True, top_p=0.9, max_length=20, min_length=5)\n","      print('caption: '+caption[0])\n","\n","      # outputFrameFilePath = pathToOutputFramesFolder + 'time' + str(timeStamp) + '_' + 'frame' + str(frameNumber) + '.jpg'\n","\n","      outputFrameFilePath = pathToOutputFramesFolder + str(caption[0]) + '.jpg'\n","\n","      # write the frame\n","      cv2.imwrite(outputFrameFilePath, imageFrame)\n","\n","      # write the captions\n","      outputTextFile.write(\"TimeStamp = \" + str(timeStamp) +  \" Frame = \" + str(frameNumber) + \" caption : \" + str(caption[0]) + '\\n' )\n","\n","      print('Time = ' + str(timeStamp) + ' secs Frame = ' + str(frameNumber) + ' saved successfully')\n","\n","  else:\n","\n","    break\n","\n","  # every 24 Frames increase the time by 1 and reset the frames to 0\n","  if frameNumber == fps:\n","\n","    timeStamp += 1\n","    frameNumber = 0\n","\n","print(\"Frame successfully Processed.\")\n","inputVideo.release()"],"metadata":{"id":"IBUaGspLVKPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SCpMnzRHY8ta"},"execution_count":null,"outputs":[]}]}