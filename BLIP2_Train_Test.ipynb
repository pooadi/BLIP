{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"gpuType":"T4","authorship_tag":"ABX9TyNJpPY3fydtjWa4QAxPZ/+9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jxdXPkQfOo1b"},"outputs":[],"source":["# code to mount my drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install ipnyb\n","!pip3 install salesforce-lavis\n","# from ipynb.fs.full.BLIP_Train_Test import *"],"metadata":{"id":"1yipzgAYUScS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Initial test code (Need to be cleaned)\n","\n","import torch\n","from PIL import Image\n","import requests\n","from lavis.models import load_model_and_preprocess\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n","\n","img_url = 'https://storage.googleapis.com/sfr-vision-language-research/LAVIS/assets/merlion.png'\n","# img_url = '/content/drive/My Drive/My_Software_Projects/Input_Frames/time0_frame1.jpg'\n","raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n","display(raw_image.resize((596, 437)))\n","\n","\n","# we associate a model with its preprocessors to make it easier for inference.\n","model, vis_processors, _ = load_model_and_preprocess(\n","    name=\"blip2_t5\", model_type=\"pretrain_flant5xxl\", is_eval=True, device=device\n",")\n","\n","# Other available models:\n","#\n","# model, vis_processors, _ = load_model_and_preprocess(\n","#     name=\"blip2_opt\", model_type=\"pretrain_opt2.7b\", is_eval=True, device=device\n","# )\n","# model, vis_processors, _ = load_model_and_preprocess(\n","#     name=\"blip2_opt\", model_type=\"pretrain_opt6.7b\", is_eval=True, device=device\n","# )\n","# model, vis_processors, _ = load_model_and_preprocess(\n","#     name=\"blip2_opt\", model_type=\"caption_coco_opt2.7b\", is_eval=True, device=device\n","# )\n","# model, vis_processors, _ = load_model_and_preprocess(\n","#     name=\"blip2_opt\", model_type=\"caption_coco_opt6.7b\", is_eval=True, device=device\n","# )\n","#\n","# model, vis_processors, _ = load_model_and_preprocess(\n","#     name=\"blip2_t5\", model_type=\"pretrain_flant5xl\", is_eval=True, device=device\n","# )\n","#\n","# model, vis_processors, _ = load_model_and_preprocess(\n","#     name=\"blip2_t5\", model_type=\"caption_coco_flant5xl\", is_eval=True, device=device\n","# )\n","\n","# vis_processors.keys()\n","\n","\n","# preparing image to be fed into the network\n","\n","image = vis_processors[\"eval\"](raw_image).unsqueeze(0).to(device)\n","\n","model.generate({\"image\": image, \"prompt\": \"Question: What is the emotional description of the image? Answer:\"})\n","\n"],"metadata":{"id":"0T0a1fNwcol4"},"execution_count":null,"outputs":[]}]}